{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f8bd67-aed0-46b9-b9e7-2ef8e8b22f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\projeto.secplab05\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c2bfd4-da07-42d6-88eb-d3d92df0a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02aa152-1c66-46fc-987a-fd67af6a1230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Ataques\n",
      "ackscan(13238071, 41)\n",
      "bruteforcedirb(481583, 41)\n",
      "cmsscan(1088524, 41)\n",
      "dosddos(734836, 41)\n",
      "fullconnectscan(13208980, 41)\n",
      "icmpechodiscover(13238071, 41)\n",
      "mysqlbruteforces(70212, 41)\n",
      "nikto(1632614, 41)\n",
      "scanvuln(13764217, 41)\n",
      "ssh_a(12243, 41)\n",
      "stealthscan(13237120, 41)\n",
      "synscan(13172535, 41)\n",
      "udpscan(51841, 41)\n",
      "wapiti(1492, 41)\n",
      "Shape Normais\n",
      "dns(49178, 41)\n",
      "http(516525, 41)\n",
      "smtp(286839, 41)\n",
      "snmp(2766, 41)\n",
      "ssh(18286, 41)\n"
     ]
    }
   ],
   "source": [
    "ataques = ['ackscan','bruteforcedirb','cmsscan','dosddos','fullconnectscan','icmpechodiscover','mysqlbruteforces','nikto','scanvuln','ssh_a','stealthscan','synscan','udpscan','wapiti']\n",
    "\n",
    "print(\"Shape Ataques\")\n",
    "for ataque in ataques:\n",
    "\n",
    "    df = pd.read_csv('dataset/in/ataque/'+ataque+'.csv')\n",
    "    print(ataque + str(df.shape))\n",
    "\n",
    "normais = ['dns','http','smtp','snmp','ssh']\n",
    "\n",
    "print(\"Shape Normais\")\n",
    "for normal in normais:\n",
    "\n",
    "    df = pd.read_csv('dataset/in/normal/'+normal+'.csv')\n",
    "    print(normal + str(df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7b09e7-6ef1-450c-8977-8256c45f8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvarMetricas(path, classifier, cm, report, acc):\n",
    "    with open(path + classifier + \".txt\", 'w') as arquivo:\n",
    "        arquivo.write(\"###\" + classifier + \"###\\n\")\n",
    "        arquivo.write(str(cm)+\"\\n\")\n",
    "        arquivo.write(report+\"\\n\")\n",
    "        arquivo.write(acc+\"\\n\")\n",
    "        arquivo.write(\"###\"+\"\\n\")\n",
    "        arquivo.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f742fb-c991-4952-a152-336d277a4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyRF(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"RandomForest\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d7412c-2e73-4a10-b72f-603eeb7bfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyDT(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"DecisionTree\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9825a3f-dc94-47d8-a9cc-29518580da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"NaiveBayes\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8333860-fa54-45fb-adc6-fb51ea0a1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyADA(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"AdaBoost\" \n",
    "    print(classifier)\n",
    "    \n",
    "    # Criar o modelo AdaBoost\n",
    "    base_estimator = DecisionTreeClassifier(max_depth=1)  # Estimador base: árvore de decisão simples\n",
    "    model = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50, random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35f87e60-1689-4434-a8b0-a1b005e1d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyKNN(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"KNN\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ecf62b4-f9fa-4d6b-8cd2-a750ffce0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyMLP(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"MPL\" \n",
    "    print(classifier)\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f59ac6e6-a7a5-45fc-9138-2c14e4d40ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyCategoricalNB(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"CategoricalNB\" \n",
    "    print(classifier)\n",
    "    model = CategoricalNB()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd489a09-20e4-4259-8c69-53999c14dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyBagging(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"Bagging\" \n",
    "    print(classifier)\n",
    "\n",
    "    # Criar o modelo Bagging\n",
    "    base_estimator = DecisionTreeClassifier(max_depth=5, random_state=16)  # Estimador base: árvore de decisão simples\n",
    "    model = BaggingClassifier(estimator=base_estimator, n_estimators=50, random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198cd63-12a8-4113-81e8-85221a7cd159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySVC(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"SVC\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = SVC(kernel=\"linear\", C=1.0, random_state=16)\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209afb16-c335-49c2-87f7-cb35ffe83548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyETC(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"ETC\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d007b0-3a2e-443a-aa9b-b7fb9db19ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLR(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"LogisticRegression\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ed841-e04e-410f-918a-164dbf587a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyGBC(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"GradientBoosting\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = GradientBoostingClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d155424-6263-429d-b976-326d2943502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyRidge(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"Ridge\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = RidgeClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8e833-e049-46d3-b722-f90196f7a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLDA(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"LDA\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2aeaa-42e4-4def-b561-ebdf5649a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPerceptron(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"Perceptron\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = Perceptron()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2c0b9-ac1c-4225-9a1c-f8df34c56a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyGPC(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"GaussianProcess\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = GaussianProcessClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5376b0-f934-49eb-ae18-0bc62c283008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySGD(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"SGD\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = SGDClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4f155-5d98-4b6f-a72d-b5735aa116ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPA(path, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    classifier = \"PassiveAggressive\" \n",
    "    print(classifier)\n",
    "    \n",
    "    model = PassiveAggressiveClassifier()\n",
    "    model.fit(X_train ,y_train)\n",
    "\n",
    "    # Salvando o modelo em um arquivo .pkl usando pickle\n",
    "    with open(path + classifier + '.pkl', 'wb') as arquivo:\n",
    "        pickle.dump(model, arquivo)\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Gerar matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=['ataque','normal'])\n",
    "    \n",
    "    print(report)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = f'Acurácia do modelo: {accuracy * 100:.2f}%'\n",
    "    print(acc)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    salvarMetricas(path, classifier, cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a3550-cbca-4809-b999-af28559fc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging\n",
      "[[15870975  1129881]\n",
      " [   14807    91484]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ataque       1.00      0.93      0.97  17000856\n",
      "      normal       0.07      0.86      0.14    106291\n",
      "\n",
      "    accuracy                           0.93  17107147\n",
      "   macro avg       0.54      0.90      0.55  17107147\n",
      "weighted avg       0.99      0.93      0.96  17107147\n",
      "\n",
      "Acurácia do modelo: 93.31%\n",
      "\n",
      "\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for i in range(6,9):\n",
    "lista = [1]\n",
    "for i in lista:\n",
    "    \n",
    "    path_dataset = 'dataset/combination_new/exp'+str(i)+'/'\n",
    "    \n",
    "    df_train = pd.read_csv(path_dataset+'train.csv')\n",
    "    X_train = df_train.drop('Label', axis=1)  \n",
    "    y_train = df_train['Label']  \n",
    "    \n",
    "    df_test = pd.read_csv(path_dataset+'test.csv')\n",
    "    X_test = df_test.drop('Label', axis=1) \n",
    "    y_test = df_test['Label']  \n",
    "    \n",
    "    #classifyRF(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    #classifyDT(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    #classifyNB(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    #classifyADA(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    #classifyMLP(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    #classifyBagging(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifySVC(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyETC(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyLR(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyGBC(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyRidge(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyLDA(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyPerceptron(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyGPC(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifySGD(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyPA(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyKNN(path_dataset, X_train, y_train, X_test, y_test)\n",
    "    classifyCategoricalNB(path_dataset, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f3b36-08c3-445d-8a60-95eb5f572799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Exemplo de labels verdadeiros e labels previstos\n",
    "y_true = [0, 10, 0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# Gera a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "\n",
    "# Acessando os valores individuais\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"Verdadeiros Negativos (TN): {tn}\")\n",
    "print(f\"Falsos Positivos (FP): {fp}\")\n",
    "print(f\"Falsos Negativos (FN): {fn}\")\n",
    "print(f\"Verdadeiros Positivos (TP): {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d908b2-2e01-41f5-9cb3-a837c2b02217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
